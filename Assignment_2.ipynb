{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpzVyy7Fk88DT3URJW+KVO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shobhit-umrao/NLP_Assignments/blob/master/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECE6Yvw77MwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import pos_tag\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, WhitespaceTokenizer, TreebankWordTokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1nPGm6f7kZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "\n",
        "import string\n",
        "import re"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7gs3DmX9Od9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fead2c39-b0d6-4888-8de2-762b05a82c6a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwAwdt1B73YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stpwd = set(stopwords.words('english'))\n",
        "\n",
        "punct = list(string.punctuation)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wecaDjwl8Die",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = ('a set of words that is complete in itself, typically containing a subject and predicate, conveying a statement, question, exclamation, or command, and consisting of a main clause and sometimes one or more subordinate clauses.')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFChoCEE-D-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c21c9105-aa36-4acd-80d4-7fdcbb39c796"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sent_tokenize(sentence)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a set of words that is complete in itself, typically containing a subject and predicate, conveying a statement, question, exclamation, or command, and consisting of a main clause and sometimes one or more subordinate clauses.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LIcNuOy-Gjc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "7e9ad94b-df8a-40ea-e914-0c1c31a44f1d"
      },
      "source": [
        "word_tokenize(sentence)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'set',\n",
              " 'of',\n",
              " 'words',\n",
              " 'that',\n",
              " 'is',\n",
              " 'complete',\n",
              " 'in',\n",
              " 'itself',\n",
              " ',',\n",
              " 'typically',\n",
              " 'containing',\n",
              " 'a',\n",
              " 'subject',\n",
              " 'and',\n",
              " 'predicate',\n",
              " ',',\n",
              " 'conveying',\n",
              " 'a',\n",
              " 'statement',\n",
              " ',',\n",
              " 'question',\n",
              " ',',\n",
              " 'exclamation',\n",
              " ',',\n",
              " 'or',\n",
              " 'command',\n",
              " ',',\n",
              " 'and',\n",
              " 'consisting',\n",
              " 'of',\n",
              " 'a',\n",
              " 'main',\n",
              " 'clause',\n",
              " 'and',\n",
              " 'sometimes',\n",
              " 'one',\n",
              " 'or',\n",
              " 'more',\n",
              " 'subordinate',\n",
              " 'clauses',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UgIEH_M-acC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "0dfa3387-2d9a-4d94-df05-b1af7ad0928a"
      },
      "source": [
        "WhitespaceTokenizer().tokenize(sentence)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'set',\n",
              " 'of',\n",
              " 'words',\n",
              " 'that',\n",
              " 'is',\n",
              " 'complete',\n",
              " 'in',\n",
              " 'itself,',\n",
              " 'typically',\n",
              " 'containing',\n",
              " 'a',\n",
              " 'subject',\n",
              " 'and',\n",
              " 'predicate,',\n",
              " 'conveying',\n",
              " 'a',\n",
              " 'statement,',\n",
              " 'question,',\n",
              " 'exclamation,',\n",
              " 'or',\n",
              " 'command,',\n",
              " 'and',\n",
              " 'consisting',\n",
              " 'of',\n",
              " 'a',\n",
              " 'main',\n",
              " 'clause',\n",
              " 'and',\n",
              " 'sometimes',\n",
              " 'one',\n",
              " 'or',\n",
              " 'more',\n",
              " 'subordinate',\n",
              " 'clauses.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Tb0max_C5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "6e765167-7c32-4aea-a95f-c2d944a84ea1"
      },
      "source": [
        "TreebankWordTokenizer().tokenize(sentence)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'set',\n",
              " 'of',\n",
              " 'words',\n",
              " 'that',\n",
              " 'is',\n",
              " 'complete',\n",
              " 'in',\n",
              " 'itself',\n",
              " ',',\n",
              " 'typically',\n",
              " 'containing',\n",
              " 'a',\n",
              " 'subject',\n",
              " 'and',\n",
              " 'predicate',\n",
              " ',',\n",
              " 'conveying',\n",
              " 'a',\n",
              " 'statement',\n",
              " ',',\n",
              " 'question',\n",
              " ',',\n",
              " 'exclamation',\n",
              " ',',\n",
              " 'or',\n",
              " 'command',\n",
              " ',',\n",
              " 'and',\n",
              " 'consisting',\n",
              " 'of',\n",
              " 'a',\n",
              " 'main',\n",
              " 'clause',\n",
              " 'and',\n",
              " 'sometimes',\n",
              " 'one',\n",
              " 'or',\n",
              " 'more',\n",
              " 'subordinate',\n",
              " 'clauses',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX9haFLQ_HEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "b6f9d82c-461e-43d4-c9cb-9af683b91fd4"
      },
      "source": [
        "sentences = sent_tokenize(sentence)\n",
        "stemmer = PorterStemmer()\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Root Word\"))\n",
        "for i in range(len(sentences)):\n",
        "    words = word_tokenize(sentences[i])\n",
        "    for word in words:\n",
        "        if (word not in stpwd and word not in punct):\n",
        "            print(\"{0:20}{1:20}\".format(word,stemmer.stem(word)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word                Root Word           \n",
            "set                 set                 \n",
            "words               word                \n",
            "complete            complet             \n",
            "typically           typic               \n",
            "containing          contain             \n",
            "subject             subject             \n",
            "predicate           predic              \n",
            "conveying           convey              \n",
            "statement           statement           \n",
            "question            question            \n",
            "exclamation         exclam              \n",
            "command             command             \n",
            "consisting          consist             \n",
            "main                main                \n",
            "clause              claus               \n",
            "sometimes           sometim             \n",
            "one                 one                 \n",
            "subordinate         subordin            \n",
            "clauses             claus               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm-xDppJ_M3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nltk_to_wordnet(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb0Wc8yU_aQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "cb455482-cf51-4ee4-881c-336412ad01ba"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "sentences = sent_tokenize(sentence)\n",
        "lematizer = WordNetLemmatizer()\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for i in range(len(sentences)):\n",
        "    words = word_tokenize(sentences[i])\n",
        "    nltk_tagged = pos_tag(words)\n",
        "    wordnet_tagged = map(lambda x:(x[0],nltk_to_wordnet(x[1])),nltk_tagged)\n",
        "    for word,tag in wordnet_tagged:\n",
        "        if (word not in stpwd and word not in punct):\n",
        "            if tag is not None:\n",
        "                print(\"{0:20}{1:20}\".format(word,lematizer.lemmatize(word,tag)))\n",
        "            else:\n",
        "                print(\"{0:20}{1:20}\".format(word,lematizer.lemmatize(word)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Word                Lemma               \n",
            "set                 set                 \n",
            "words               word                \n",
            "complete            complete            \n",
            "typically           typically           \n",
            "containing          contain             \n",
            "subject             subject             \n",
            "predicate           predicate           \n",
            "conveying           convey              \n",
            "statement           statement           \n",
            "question            question            \n",
            "exclamation         exclamation         \n",
            "command             command             \n",
            "consisting          consist             \n",
            "main                main                \n",
            "clause              clause              \n",
            "sometimes           sometimes           \n",
            "one                 one                 \n",
            "subordinate         subordinate         \n",
            "clauses             clause              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnOVmX-n_iYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "06e0e040-5428-4644-e664-2e41075567d4"
      },
      "source": [
        "nltk_taged = pos_tag(['I','am','smart','kid'])\n",
        "wordnet_tagged = map(lambda x:(x[0],nltk_to_wordnet(x[1])),nltk_taged)\n",
        "for word,tag in wordnet_tagged:\n",
        "    print(f\"{word}----->{tag}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I----->None\n",
            "am----->v\n",
            "smart----->a\n",
            "kid----->n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9XHx7mLAFEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}